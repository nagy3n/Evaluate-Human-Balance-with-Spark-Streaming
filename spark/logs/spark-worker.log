[38;5;6m [38;5;5m15:39:06.96 [0m
[38;5;6m [38;5;5m15:39:06.96 [0m[1mWelcome to the Bitnami spark container[0m
[38;5;6m [38;5;5m15:39:06.96 [0mSubscribe to project updates by watching [1mhttps://github.com/bitnami/bitnami-docker-spark[0m
[38;5;6m [38;5;5m15:39:06.96 [0mSubmit issues and feature requests at [1mhttps://github.com/bitnami/bitnami-docker-spark/issues[0m
[38;5;6m [38;5;5m15:39:06.97 [0m
[38;5;6m [38;5;5m15:39:06.98 [0m[38;5;2mINFO [0m ==> ** Starting Spark setup **
[38;5;6m [38;5;5m15:39:06.99 [0m[38;5;2mINFO [0m ==> Generating Spark configuration file...
[38;5;6m [38;5;5m15:39:07.00 [0m[38;5;2mINFO [0m ==> ** Spark setup finished! **

[38;5;6m [38;5;5m15:39:07.01 [0m[38;5;2mINFO [0m ==> ** Starting Spark in worker mode **
This script is deprecated, use start-worker.sh
starting org.apache.spark.deploy.worker.Worker, logging to /opt/bitnami/spark/logs/spark--org.apache.spark.deploy.worker.Worker-1-02f276440417.out
Spark Command: /opt/bitnami/java/bin/java -cp /opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://spark:7077
========================================
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/05/04 15:39:09 INFO Worker: Started daemon with process name: 41@02f276440417
21/05/04 15:39:09 INFO SignalUtils: Registering signal handler for TERM
21/05/04 15:39:09 INFO SignalUtils: Registering signal handler for HUP
21/05/04 15:39:09 INFO SignalUtils: Registering signal handler for INT
21/05/04 15:39:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/05/04 15:39:11 INFO SecurityManager: Changing view acls to: spark
21/05/04 15:39:11 INFO SecurityManager: Changing modify acls to: spark
21/05/04 15:39:11 INFO SecurityManager: Changing view acls groups to: 
21/05/04 15:39:11 INFO SecurityManager: Changing modify acls groups to: 
21/05/04 15:39:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
21/05/04 15:39:12 INFO Utils: Successfully started service 'sparkWorker' on port 46587.
21/05/04 15:39:12 INFO Worker: Worker decommissioning not enabled, SIGPWR will result in exiting.
21/05/04 15:39:13 INFO Worker: Starting Spark worker 172.30.0.4:46587 with 1 cores, 1024.0 MiB RAM
21/05/04 15:39:13 INFO Worker: Running Spark version 3.1.1
21/05/04 15:39:13 INFO Worker: Spark home: /opt/bitnami/spark
21/05/04 15:39:13 INFO ResourceUtils: ==============================================================
21/05/04 15:39:13 INFO ResourceUtils: No custom resources configured for spark.worker.
21/05/04 15:39:13 INFO ResourceUtils: ==============================================================
21/05/04 15:39:14 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
21/05/04 15:39:14 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://02f276440417:8081
21/05/04 15:39:14 INFO Worker: Connecting to master spark:7077...
21/05/04 15:39:14 WARN Worker: Failed to connect to master spark:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.worker.Worker$$anon$1.run(Worker.scala:298)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to spark/172.30.0.5:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:287)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:230)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: spark/172.30.0.5:7077
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:702)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
21/05/04 15:39:28 INFO Worker: Retrying connection to master (attempt # 1)
21/05/04 15:39:28 INFO Worker: Connecting to master spark:7077...
21/05/04 15:39:28 INFO TransportClientFactory: Successfully created connection to spark/172.30.0.5:7077 after 12 ms (0 ms spent in bootstraps)
21/05/04 15:39:28 INFO Worker: Successfully registered with master spark://d3234510d112:7077
